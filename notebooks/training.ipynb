{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = os.path.join(os.getcwd(), '../')\n",
    "data_directory = os.path.join(root_directory ,'data')\n",
    "pickle_name = 'After_preprocessing_raw_pickle'\n",
    "pickle_path = os.path.join(data_directory, pickle_name)\n",
    "raw_data = pd.read_pickle(pickle_path)\n",
    "day_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "direction_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "merged_data = raw_data\n",
    "merged_data = merged_data.drop(columns=['Report Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['Route'] = merged_data['Route'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Route          int64\n",
       "Direction     object\n",
       "hour           int64\n",
       "Day           object\n",
       "Year           int64\n",
       "Month          int64\n",
       "Daym           int64\n",
       "target       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col_int = ['hour', 'Month', 'Daym', 'Route', 'Year']\n",
    "categorical_col_str = ['Direction', 'Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(merged_data, test_size=0.3)\n",
    "train, val = train_test_split(train, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_datset(dataframe, shuffle=True, batch_size=1280):\n",
    "    df = merged_data.copy()\n",
    "    labels = df.pop('target')\n",
    "    df = {key: value[:, tf.newaxis] for key, value in merged_data.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df, labels))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_ds = df_to_datset(train)\n",
    "test_ds = df_to_datset(test)\n",
    "val_ds = df_to_datset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens = max_tokens)\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    index.adapt(feature_ds)\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# for header in categorical_col_int:\n",
    "#     categorical_int_col = tf.keras.Input(shape=(1,), name=header, dtype='int64', )\n",
    "#     encoding_layer = get_category_encoding_layer(name=header, dataset=train_ds, dtype='int64')\n",
    "#     encoded_categorical_col = encoding_layer(categorical_col_int)\n",
    "#     all_inputs.append(categorical_int_col)\n",
    "#     encoded_features.append(encoded_categorical_col)\n",
    "\n",
    "for header in categorical_col_str:\n",
    "    categorical_str_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(name=header, dataset=train_ds, dtype='string')\n",
    "    encoded_categorical_col = encoding_layer(categorical_str_col)\n",
    "    all_inputs.append(categorical_str_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for header in categorical_col_int:\n",
    "    categorical_int_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "    encoding_layer = get_category_encoding_layer(name=header, dataset=train_ds, dtype='int64', max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_int_col)\n",
    "    all_inputs.append(categorical_int_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(min_delta=0.01,monitor='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test/lib/python3.7/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['target'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2401/2401 [==============================] - 38s 15ms/step - loss: 0.0917 - accuracy: 0.9821 - val_loss: 0.1045 - val_accuracy: 0.9825\n",
      "Epoch 2/10\n",
      "2401/2401 [==============================] - 37s 15ms/step - loss: 0.0771 - accuracy: 0.9825 - val_loss: 0.0959 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2c3faf310>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds, callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2401/2401 [==============================] - 18s 8ms/step - loss: 0.0959 - accuracy: 0.9825\n",
      "Accuracy 0.9824689626693726\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'Route': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'Direction': TensorSpec(shape=(None, 1), dtype=tf.string, name=None), 'hour': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'Day': TensorSpec(shape=(None, 1), dtype=tf.string, name=None), 'Year': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'Month': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'Daym': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'target': TensorSpec(shape=(None, 1), dtype=tf.float64, name=None)}, TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8aac0b6a3e67f35bcd67088a857342b2a6b50e1135570ee0f841fb10732c056"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
